{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Introduction**\n",
    "\n",
    "# NetTrafficGuard EDA\n",
    "\n",
    "*This notebook is designed to perform Exploratory Data Analysis (EDA) on network traffic datasets. The goal is to understand the structure of the data, identify patterns, and prepare the data for further analysis and modeling. We will follow a structured approach to EDA, including generating questions, applying visualization techniques, transforming and modeling data, and refining our analysis based on insights.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Import Libraries**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Set plotting aesthetics\n",
    "sns.set(style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. Load Data**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                      Flow ID         Src IP  Src Port  \\\n",
       " 0     10.152.152.11-216.58.220.99-57158-443-6  10.152.152.11     57158   \n",
       " 1     10.152.152.11-216.58.220.99-57159-443-6  10.152.152.11     57159   \n",
       " 2     10.152.152.11-216.58.220.99-57160-443-6  10.152.152.11     57160   \n",
       " 3    10.152.152.11-74.125.136.120-49134-443-6  10.152.152.11     49134   \n",
       " 4  10.152.152.11-173.194.65.127-34697-19305-6  10.152.152.11     34697   \n",
       " \n",
       "            Dst IP  Dst Port  Protocol               Timestamp  Flow Duration  \\\n",
       " 0   216.58.220.99       443         6  24/07/2015 04:09:48 PM            229   \n",
       " 1   216.58.220.99       443         6  24/07/2015 04:09:48 PM            407   \n",
       " 2   216.58.220.99       443         6  24/07/2015 04:09:48 PM            431   \n",
       " 3  74.125.136.120       443         6  24/07/2015 04:09:48 PM            359   \n",
       " 4  173.194.65.127     19305         6  24/07/2015 04:09:45 PM       10778451   \n",
       " \n",
       "    Total Fwd Packet  Total Bwd packets  ...  Active Mean  Active Std  \\\n",
       " 0                 1                  1  ...            0           0   \n",
       " 1                 1                  1  ...            0           0   \n",
       " 2                 1                  1  ...            0           0   \n",
       " 3                 1                  1  ...            0           0   \n",
       " 4               591                400  ...            0           0   \n",
       " \n",
       "    Active Max  Active Min     Idle Mean      Idle Std      Idle Max  \\\n",
       " 0           0           0  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       " 1           0           0  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       " 2           0           0  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       " 3           0           0  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       " 4           0           0  1.437765e+15  3.117718e+06  1.437765e+15   \n",
       " \n",
       "        Idle Min    Label          Label.1  \n",
       " 0  0.000000e+00  Non-Tor  AUDIO-STREAMING  \n",
       " 1  0.000000e+00  Non-Tor  AUDIO-STREAMING  \n",
       " 2  0.000000e+00  Non-Tor  AUDIO-STREAMING  \n",
       " 3  0.000000e+00  Non-Tor  AUDIO-STREAMING  \n",
       " 4  1.437765e+15  Non-Tor  AUDIO-STREAMING  \n",
       " \n",
       " [5 rows x 85 columns],\n",
       "    0    1     2   3    4     5   6   7   8   9   ...  32   33   34    35   36  \\\n",
       " 0   0  tcp  http  SF  181  5450   0   0   0   0  ...   9  1.0  0.0  0.11  0.0   \n",
       " 1   0  tcp  http  SF  239   486   0   0   0   0  ...  19  1.0  0.0  0.05  0.0   \n",
       " 2   0  tcp  http  SF  235  1337   0   0   0   0  ...  29  1.0  0.0  0.03  0.0   \n",
       " 3   0  tcp  http  SF  219  1337   0   0   0   0  ...  39  1.0  0.0  0.03  0.0   \n",
       " 4   0  tcp  http  SF  217  2032   0   0   0   0  ...  49  1.0  0.0  0.02  0.0   \n",
       " \n",
       "     37   38   39   40       41  \n",
       " 0  0.0  0.0  0.0  0.0  normal.  \n",
       " 1  0.0  0.0  0.0  0.0  normal.  \n",
       " 2  0.0  0.0  0.0  0.0  normal.  \n",
       " 3  0.0  0.0  0.0  0.0  normal.  \n",
       " 4  0.0  0.0  0.0  0.0  normal.  \n",
       " \n",
       " [5 rows x 42 columns],\n",
       "    0   tcp   private   REJ    0.1    0.2  0.3  0.4  0.5  0.6  ...  0.04.1  \\\n",
       " 0  0   tcp   private   REJ      0      0    0    0    0    0  ...    0.00   \n",
       " 1  2   tcp  ftp_data    SF  12983      0    0    0    0    0  ...    0.61   \n",
       " 2  0  icmp     eco_i    SF     20      0    0    0    0    0  ...    1.00   \n",
       " 3  1   tcp    telnet  RSTO      0     15    0    0    0    0  ...    0.31   \n",
       " 4  0   tcp      http    SF    267  14515    0    0    0    0  ...    1.00   \n",
       " \n",
       "    0.06.1  0.22  0.23  0.24  0.25   1.2   1.3  neptune  21  \n",
       " 0    0.06  0.00  0.00  0.00   0.0  1.00  1.00  neptune  21  \n",
       " 1    0.04  0.61  0.02  0.00   0.0  0.00  0.00   normal  21  \n",
       " 2    0.00  1.00  0.28  0.00   0.0  0.00  0.00    saint  15  \n",
       " 3    0.17  0.03  0.02  0.00   0.0  0.83  0.71    mscan  11  \n",
       " 4    0.00  0.01  0.03  0.01   0.0  0.00  0.00   normal  21  \n",
       " \n",
       " [5 rows x 43 columns])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define paths to datasets\n",
    "cicids_path = 'E:\\\\Hackatone Project\\\\NetTrafficGuard\\\\data\\\\raw\\\\CICIDS2017\\\\Darknet.csv'\n",
    "kddcup_path = 'E:\\\\Hackatone Project\\\\NetTrafficGuard\\\\data\\\\raw\\KDDCup1999\\\\kddcup.data_10_percent_corrected'\n",
    "nsl_kdd_path = 'E:\\\\Hackatone Project\\\\NetTrafficGuard\\\\data\\\\raw\\\\NSL-KDD\\KDDTest+.csv'\n",
    "\n",
    "# Load datasets\n",
    "cicids_data = pd.read_csv(cicids_path)\n",
    "kddcup_data = pd.read_csv(kddcup_path, header=None)\n",
    "nsl_kdd_data = pd.read_csv(nsl_kdd_path)\n",
    "\n",
    "# Display the first few rows of each dataset\n",
    "cicids_data.head(), kddcup_data.head(), nsl_kdd_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. Generate Questions**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate Questions\n",
    "\n",
    "Generating questions is a crucial step in exploratory data analysis (EDA). It involves formulating specific queries that guide the analysis and help uncover insights from the data. Below are some fundamental questions that guide our EDA for the NetTrafficGuard project:\n",
    "\n",
    "### 4.1 What are the basic statistics and structure of each dataset?\n",
    "\n",
    "Understanding the basic statistics and structure of each dataset provides a foundation for further analysis. This includes:\n",
    "\n",
    "- **Descriptive Statistics:** Mean, median, mode, standard deviation, minimum, and maximum values for numerical features.\n",
    "- **Data Types:** Identifying the type of each feature (e.g., numerical, categorical, date/time).\n",
    "- **Shape and Size:** Number of rows and columns in the dataset.\n",
    "- **Data Distribution:** Distribution of values in key columns to understand their range and skewness.\n",
    "\n",
    "*Example Questions:*\n",
    "- What is the distribution of numerical features in the dataset?\n",
    "- How many features are there, and what types are they?\n",
    "- Are there any unexpected data types or formats in the dataset?\n",
    "\n",
    "### 4.2 Are there any missing values in the datasets?\n",
    "\n",
    "Identifying missing values is essential to ensure the completeness of the dataset. This includes:\n",
    "\n",
    "- **Missing Value Counts:** Number of missing values per column.\n",
    "- **Patterns of Missing Data:** Are missing values randomly distributed, or do they follow a specific pattern?\n",
    "- **Handling Strategies:** Methods to address missing values, such as imputation or removal.\n",
    "\n",
    "*Example Questions:*\n",
    "- Which columns have missing values, and what percentage of data is missing?\n",
    "- Are there specific rows or columns with disproportionately high amounts of missing data?\n",
    "- What strategies can be applied to handle missing data in different columns?\n",
    "\n",
    "### 4.3 What are the key features in each dataset, and how do they correlate with each other?\n",
    "\n",
    "Understanding the key features and their relationships helps to identify patterns and insights. This includes:\n",
    "\n",
    "- **Feature Importance:** Determining which features are most relevant for the analysis or model.\n",
    "- **Correlation Analysis:** Examining the correlation between numerical features to identify potential relationships.\n",
    "- **Categorical Feature Analysis:** Analyzing distributions and relationships among categorical features.\n",
    "\n",
    "*Example Questions:*\n",
    "- Which features have the highest correlation with the target variable (if applicable)?\n",
    "- Are there any multicollinearity issues among numerical features?\n",
    "- How do categorical features impact numerical features, if at all?\n",
    "\n",
    "### 4.4 Are there any patterns or anomalies in the data?\n",
    "\n",
    "Identifying patterns and anomalies can reveal underlying trends or issues within the dataset. This includes:\n",
    "\n",
    "- **Pattern Detection:** Recognizing regular patterns or trends within the data.\n",
    "- **Anomaly Detection:** Identifying data points that deviate significantly from the norm, which could indicate errors or outliers.\n",
    "- **Temporal Analysis:** For time-series data, analyzing trends over time.\n",
    "\n",
    "*Example Questions:*\n",
    "- Are there any seasonal or temporal patterns in the dataset?\n",
    "- Are there outliers or anomalies in key features that need further investigation?\n",
    "- How do patterns vary across different segments of the data?\n",
    "\n",
    "### 4.5 How do different features impact the target variable (if applicable)?\n",
    "\n",
    "Understanding the relationship between features and the target variable is critical for building predictive models. This includes:\n",
    "\n",
    "- **Feature-Target Analysis:** Assessing how different features influence the target variable.\n",
    "- **Feature Importance:** Using statistical methods to determine the importance of each feature in predicting the target variable.\n",
    "- **Interaction Effects:** Exploring interactions between features and their combined impact on the target variable.\n",
    "\n",
    "*Example Questions:*\n",
    "- Which features have the most significant impact on the target variable?\n",
    "- Are there any interaction effects between features that influence the target variable?\n",
    "- How can feature selection improve the performance of predictive models?\n",
    "\n",
    "By addressing these questions, you will gain a comprehensive understanding of the datasets and uncover valuable insights that inform subsequent analysis and model development.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **5. Data Cleaning**\n",
    "<hr>\n",
    "<p>Data cleaning is a critical part of the data preprocessing pipeline, ensuring that our dataset is accurate, complete, and ready for analysis. Below, we perform a detailed data cleaning process on each dataset, addressing missing values, outliers, and other anomalies.</p>\n",
    "\n",
    "## **5.1 CICIDS2017 Data Cleaning**\n",
    "\n",
    "<strong> 5.1.1 Load and Inspect Data </strong>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CICIDS2017 Data Overview:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 158616 entries, 0 to 158615\n",
      "Data columns (total 85 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   Flow ID                     158616 non-null  object \n",
      " 1   Src IP                      158616 non-null  object \n",
      " 2   Src Port                    158616 non-null  int64  \n",
      " 3   Dst IP                      158616 non-null  object \n",
      " 4   Dst Port                    158616 non-null  int64  \n",
      " 5   Protocol                    158616 non-null  int64  \n",
      " 6   Timestamp                   158616 non-null  object \n",
      " 7   Flow Duration               158616 non-null  int64  \n",
      " 8   Total Fwd Packet            158616 non-null  int64  \n",
      " 9   Total Bwd packets           158616 non-null  int64  \n",
      " 10  Total Length of Fwd Packet  158616 non-null  int64  \n",
      " 11  Total Length of Bwd Packet  158616 non-null  int64  \n",
      " 12  Fwd Packet Length Max       158616 non-null  int64  \n",
      " 13  Fwd Packet Length Min       158616 non-null  int64  \n",
      " 14  Fwd Packet Length Mean      158616 non-null  float64\n",
      " 15  Fwd Packet Length Std       158616 non-null  float64\n",
      " 16  Bwd Packet Length Max       158616 non-null  int64  \n",
      " 17  Bwd Packet Length Min       158616 non-null  int64  \n",
      " 18  Bwd Packet Length Mean      158616 non-null  float64\n",
      " 19  Bwd Packet Length Std       158616 non-null  float64\n",
      " 20  Flow Bytes/s                158568 non-null  float64\n",
      " 21  Flow Packets/s              158616 non-null  float64\n",
      " 22  Flow IAT Mean               158616 non-null  float64\n",
      " 23  Flow IAT Std                158616 non-null  float64\n",
      " 24  Flow IAT Max                158616 non-null  int64  \n",
      " 25  Flow IAT Min                158616 non-null  int64  \n",
      " 26  Fwd IAT Total               158616 non-null  int64  \n",
      " 27  Fwd IAT Mean                158616 non-null  float64\n",
      " 28  Fwd IAT Std                 158616 non-null  float64\n",
      " 29  Fwd IAT Max                 158616 non-null  int64  \n",
      " 30  Fwd IAT Min                 158616 non-null  int64  \n",
      " 31  Bwd IAT Total               158616 non-null  int64  \n",
      " 32  Bwd IAT Mean                158616 non-null  float64\n",
      " 33  Bwd IAT Std                 158616 non-null  float64\n",
      " 34  Bwd IAT Max                 158616 non-null  int64  \n",
      " 35  Bwd IAT Min                 158616 non-null  int64  \n",
      " 36  Fwd PSH Flags               158616 non-null  int64  \n",
      " 37  Bwd PSH Flags               158616 non-null  int64  \n",
      " 38  Fwd URG Flags               158616 non-null  int64  \n",
      " 39  Bwd URG Flags               158616 non-null  int64  \n",
      " 40  Fwd Header Length           158616 non-null  int64  \n",
      " 41  Bwd Header Length           158616 non-null  int64  \n",
      " 42  Fwd Packets/s               158616 non-null  float64\n",
      " 43  Bwd Packets/s               158616 non-null  float64\n",
      " 44  Packet Length Min           158616 non-null  int64  \n",
      " 45  Packet Length Max           158616 non-null  int64  \n",
      " 46  Packet Length Mean          158616 non-null  float64\n",
      " 47  Packet Length Std           158616 non-null  float64\n",
      " 48  Packet Length Variance      158616 non-null  float64\n",
      " 49  FIN Flag Count              158616 non-null  int64  \n",
      " 50  SYN Flag Count              158616 non-null  int64  \n",
      " 51  RST Flag Count              158616 non-null  int64  \n",
      " 52  PSH Flag Count              158616 non-null  int64  \n",
      " 53  ACK Flag Count              158616 non-null  int64  \n",
      " 54  URG Flag Count              158616 non-null  int64  \n",
      " 55  CWE Flag Count              158616 non-null  int64  \n",
      " 56  ECE Flag Count              158616 non-null  int64  \n",
      " 57  Down/Up Ratio               158616 non-null  int64  \n",
      " 58  Average Packet Size         158616 non-null  float64\n",
      " 59  Fwd Segment Size Avg        158616 non-null  float64\n",
      " 60  Bwd Segment Size Avg        158616 non-null  float64\n",
      " 61  Fwd Bytes/Bulk Avg          158616 non-null  int64  \n",
      " 62  Fwd Packet/Bulk Avg         158616 non-null  int64  \n",
      " 63  Fwd Bulk Rate Avg           158616 non-null  int64  \n",
      " 64  Bwd Bytes/Bulk Avg          158616 non-null  int64  \n",
      " 65  Bwd Packet/Bulk Avg         158616 non-null  int64  \n",
      " 66  Bwd Bulk Rate Avg           158616 non-null  int64  \n",
      " 67  Subflow Fwd Packets         158616 non-null  int64  \n",
      " 68  Subflow Fwd Bytes           158616 non-null  int64  \n",
      " 69  Subflow Bwd Packets         158616 non-null  int64  \n",
      " 70  Subflow Bwd Bytes           158616 non-null  int64  \n",
      " 71  FWD Init Win Bytes          158616 non-null  int64  \n",
      " 72  Bwd Init Win Bytes          158616 non-null  int64  \n",
      " 73  Fwd Act Data Pkts           158616 non-null  int64  \n",
      " 74  Fwd Seg Size Min            158616 non-null  int64  \n",
      " 75  Active Mean                 158616 non-null  int64  \n",
      " 76  Active Std                  158616 non-null  int64  \n",
      " 77  Active Max                  158616 non-null  int64  \n",
      " 78  Active Min                  158616 non-null  int64  \n",
      " 79  Idle Mean                   158616 non-null  float64\n",
      " 80  Idle Std                    158616 non-null  float64\n",
      " 81  Idle Max                    158616 non-null  float64\n",
      " 82  Idle Min                    158616 non-null  float64\n",
      " 83  Label                       158616 non-null  object \n",
      " 84  Label.1                     158616 non-null  object \n",
      "dtypes: float64(24), int64(55), object(6)\n",
      "memory usage: 102.9+ MB\n",
      "None\n",
      "                                      Flow ID         Src IP  Src Port  \\\n",
      "0     10.152.152.11-216.58.220.99-57158-443-6  10.152.152.11     57158   \n",
      "1     10.152.152.11-216.58.220.99-57159-443-6  10.152.152.11     57159   \n",
      "2     10.152.152.11-216.58.220.99-57160-443-6  10.152.152.11     57160   \n",
      "3    10.152.152.11-74.125.136.120-49134-443-6  10.152.152.11     49134   \n",
      "4  10.152.152.11-173.194.65.127-34697-19305-6  10.152.152.11     34697   \n",
      "\n",
      "           Dst IP  Dst Port  Protocol               Timestamp  Flow Duration  \\\n",
      "0   216.58.220.99       443         6  24/07/2015 04:09:48 PM            229   \n",
      "1   216.58.220.99       443         6  24/07/2015 04:09:48 PM            407   \n",
      "2   216.58.220.99       443         6  24/07/2015 04:09:48 PM            431   \n",
      "3  74.125.136.120       443         6  24/07/2015 04:09:48 PM            359   \n",
      "4  173.194.65.127     19305         6  24/07/2015 04:09:45 PM       10778451   \n",
      "\n",
      "   Total Fwd Packet  Total Bwd packets  ...  Active Mean  Active Std  \\\n",
      "0                 1                  1  ...            0           0   \n",
      "1                 1                  1  ...            0           0   \n",
      "2                 1                  1  ...            0           0   \n",
      "3                 1                  1  ...            0           0   \n",
      "4               591                400  ...            0           0   \n",
      "\n",
      "   Active Max  Active Min     Idle Mean      Idle Std      Idle Max  \\\n",
      "0           0           0  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "1           0           0  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "2           0           0  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "3           0           0  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "4           0           0  1.437765e+15  3.117718e+06  1.437765e+15   \n",
      "\n",
      "       Idle Min    Label          Label.1  \n",
      "0  0.000000e+00  Non-Tor  AUDIO-STREAMING  \n",
      "1  0.000000e+00  Non-Tor  AUDIO-STREAMING  \n",
      "2  0.000000e+00  Non-Tor  AUDIO-STREAMING  \n",
      "3  0.000000e+00  Non-Tor  AUDIO-STREAMING  \n",
      "4  1.437765e+15  Non-Tor  AUDIO-STREAMING  \n",
      "\n",
      "[5 rows x 85 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Display basic information and initial rows of the dataset\n",
    "print(\"CICIDS2017 Data Overview:\")\n",
    "print(cicids_data.info())\n",
    "print(cicids_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values Analysis:\n",
      "Columns with Missing Values:\n",
      "Flow Bytes/s    48\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing Values Analysis:\")\n",
    "missing_values_cicids = cicids_data.isnull().sum()\n",
    "missing_values_summary = missing_values_cicids[missing_values_cicids > 0]\n",
    "\n",
    "print(\"Columns with Missing Values:\")\n",
    "print(missing_values_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **5.1.3 Advanced Outlier Detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outlier Detection:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rahul\\.conda\\envs\\nettrafficguard\\lib\\site-packages\\numpy\\_core\\_methods.py:185: RuntimeWarning: invalid value encountered in subtract\n",
      "  x = asanyarray(arr - arrmean)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers detected in columns:\n",
      "Total Fwd Packet                532\n",
      "Total Bwd packets               472\n",
      "Total Length of Fwd Packet      327\n",
      "Total Length of Bwd Packet      259\n",
      "Fwd Packet Length Max           136\n",
      "Fwd Packet Length Min          1709\n",
      "Fwd Packet Length Mean         2228\n",
      "Fwd Packet Length Std          3050\n",
      "Bwd Packet Length Max           278\n",
      "Bwd Packet Length Min          7207\n",
      "Bwd Packet Length Mean         4954\n",
      "Bwd Packet Length Std          2543\n",
      "Flow IAT Mean                  3154\n",
      "Flow IAT Std                   3341\n",
      "Flow IAT Max                   2956\n",
      "Flow IAT Min                   1940\n",
      "Fwd IAT Mean                   5123\n",
      "Fwd IAT Std                    4019\n",
      "Fwd IAT Max                    2991\n",
      "Fwd IAT Min                    4536\n",
      "Bwd IAT Mean                   4423\n",
      "Bwd IAT Std                    4421\n",
      "Bwd IAT Max                    3329\n",
      "Bwd IAT Min                    3537\n",
      "Fwd PSH Flags                 15084\n",
      "Fwd Header Length               542\n",
      "Bwd Header Length               467\n",
      "Fwd Packets/s                  1838\n",
      "Bwd Packets/s                  3974\n",
      "Packet Length Min              2378\n",
      "Packet Length Max               268\n",
      "Packet Length Mean             4088\n",
      "Packet Length Std               269\n",
      "Packet Length Variance          144\n",
      "SYN Flag Count                    3\n",
      "RST Flag Count                 1517\n",
      "PSH Flag Count                  969\n",
      "ACK Flag Count                  542\n",
      "Down/Up Ratio                     8\n",
      "Average Packet Size            3771\n",
      "Fwd Segment Size Avg           2228\n",
      "Bwd Segment Size Avg           4954\n",
      "Bwd Packet/Bulk Avg             722\n",
      "Bwd Bulk Rate Avg               287\n",
      "Subflow Fwd Bytes              2130\n",
      "Subflow Bwd Bytes              4578\n",
      "FWD Init Win Bytes             2044\n",
      "Bwd Init Win Bytes             2011\n",
      "Fwd Act Data Pkts               689\n",
      "Fwd Seg Size Min                 34\n",
      "Idle Std                       6546\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Detect outliers using Z-score method\n",
    "from scipy import stats\n",
    "\n",
    "print(\"\\nOutlier Detection:\")\n",
    "z_scores = np.abs(stats.zscore(cicids_data.select_dtypes(include=[np.number])))\n",
    "outliers = (z_scores > 3).sum(axis=0)\n",
    "print(\"Outliers detected in columns:\")\n",
    "print(outliers[outliers > 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **5.1.4 Handle Missing Values and Outliers**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dropping Columns with > 50% Missing Values:\n",
      "\n",
      "Handling Outliers:\n",
      "\n",
      "Removing Duplicate Rows:\n",
      "\n",
      "Saving Cleaned CICIDS2017 Data:\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values: Drop columns with more than 50% missing values\n",
    "print(\"\\nDropping Columns with > 50% Missing Values:\")\n",
    "threshold = len(cicids_data) * 0.5\n",
    "cicids_data_clean = cicids_data.dropna(thresh=threshold, axis=1)\n",
    "\n",
    "# Handle outliers: Cap values at 99th percentile\n",
    "print(\"\\nHandling Outliers:\")\n",
    "for col in cicids_data_clean.select_dtypes(include=[np.number]).columns:\n",
    "    cap_value = cicids_data_clean[col].quantile(0.99)\n",
    "    cicids_data_clean[col] = np.where(cicids_data_clean[col] > cap_value, cap_value, cicids_data_clean[col])\n",
    "\n",
    "# Remove duplicates\n",
    "print(\"\\nRemoving Duplicate Rows:\")\n",
    "cicids_data_clean = cicids_data_clean.drop_duplicates()\n",
    "\n",
    "# Save cleaned data\n",
    "print(\"\\nSaving Cleaned CICIDS2017 Data:\")\n",
    "cicids_data_clean.to_csv('E:\\\\Hackatone Project\\\\NetTrafficGuard\\\\data\\\\processed\\\\processedCICIDS2017_Cleaned.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **5.2 KDD Cup 1999 Data Cleaning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **5.2.1 Load and Inspect Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KDD Cup 1999 Data Overview:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 494021 entries, 0 to 494020\n",
      "Data columns (total 42 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   0       494021 non-null  int64  \n",
      " 1   1       494021 non-null  object \n",
      " 2   2       494021 non-null  object \n",
      " 3   3       494021 non-null  object \n",
      " 4   4       494021 non-null  int64  \n",
      " 5   5       494021 non-null  int64  \n",
      " 6   6       494021 non-null  int64  \n",
      " 7   7       494021 non-null  int64  \n",
      " 8   8       494021 non-null  int64  \n",
      " 9   9       494021 non-null  int64  \n",
      " 10  10      494021 non-null  int64  \n",
      " 11  11      494021 non-null  int64  \n",
      " 12  12      494021 non-null  int64  \n",
      " 13  13      494021 non-null  int64  \n",
      " 14  14      494021 non-null  int64  \n",
      " 15  15      494021 non-null  int64  \n",
      " 16  16      494021 non-null  int64  \n",
      " 17  17      494021 non-null  int64  \n",
      " 18  18      494021 non-null  int64  \n",
      " 19  19      494021 non-null  int64  \n",
      " 20  20      494021 non-null  int64  \n",
      " 21  21      494021 non-null  int64  \n",
      " 22  22      494021 non-null  int64  \n",
      " 23  23      494021 non-null  int64  \n",
      " 24  24      494021 non-null  float64\n",
      " 25  25      494021 non-null  float64\n",
      " 26  26      494021 non-null  float64\n",
      " 27  27      494021 non-null  float64\n",
      " 28  28      494021 non-null  float64\n",
      " 29  29      494021 non-null  float64\n",
      " 30  30      494021 non-null  float64\n",
      " 31  31      494021 non-null  int64  \n",
      " 32  32      494021 non-null  int64  \n",
      " 33  33      494021 non-null  float64\n",
      " 34  34      494021 non-null  float64\n",
      " 35  35      494021 non-null  float64\n",
      " 36  36      494021 non-null  float64\n",
      " 37  37      494021 non-null  float64\n",
      " 38  38      494021 non-null  float64\n",
      " 39  39      494021 non-null  float64\n",
      " 40  40      494021 non-null  float64\n",
      " 41  41      494021 non-null  object \n",
      "dtypes: float64(15), int64(23), object(4)\n",
      "memory usage: 158.3+ MB\n",
      "None\n",
      "   0    1     2   3    4     5   6   7   8   9   ...  32   33   34    35   36  \\\n",
      "0   0  tcp  http  SF  181  5450   0   0   0   0  ...   9  1.0  0.0  0.11  0.0   \n",
      "1   0  tcp  http  SF  239   486   0   0   0   0  ...  19  1.0  0.0  0.05  0.0   \n",
      "2   0  tcp  http  SF  235  1337   0   0   0   0  ...  29  1.0  0.0  0.03  0.0   \n",
      "3   0  tcp  http  SF  219  1337   0   0   0   0  ...  39  1.0  0.0  0.03  0.0   \n",
      "4   0  tcp  http  SF  217  2032   0   0   0   0  ...  49  1.0  0.0  0.02  0.0   \n",
      "\n",
      "    37   38   39   40       41  \n",
      "0  0.0  0.0  0.0  0.0  normal.  \n",
      "1  0.0  0.0  0.0  0.0  normal.  \n",
      "2  0.0  0.0  0.0  0.0  normal.  \n",
      "3  0.0  0.0  0.0  0.0  normal.  \n",
      "4  0.0  0.0  0.0  0.0  normal.  \n",
      "\n",
      "[5 rows x 42 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Display basic information and initial rows of the dataset\n",
    "print(\"KDD Cup 1999 Data Overview:\")\n",
    "print(kddcup_data.info())\n",
    "print(kddcup_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **5.2.2 Detailed Missing Value Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values Analysis:\n",
      "Columns with Missing Values:\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing Values Analysis:\")\n",
    "missing_values_kddcup = kddcup_data.isnull().sum()\n",
    "missing_values_summary = missing_values_kddcup[missing_values_kddcup > 0]\n",
    "\n",
    "print(\"Columns with Missing Values:\")\n",
    "print(missing_values_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **5.2.3 Advanced Outlier Detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outlier Detection:\n",
      "Outliers detected in columns:\n",
      "0      12350\n",
      "4       4834\n",
      "5      85763\n",
      "6         22\n",
      "7       1238\n",
      "8          4\n",
      "9       3192\n",
      "10        63\n",
      "11     73237\n",
      "12      2224\n",
      "13        55\n",
      "14        12\n",
      "15       585\n",
      "16       265\n",
      "17        51\n",
      "18       454\n",
      "21       685\n",
      "24     89234\n",
      "25     88335\n",
      "26     29073\n",
      "27     29701\n",
      "28    111942\n",
      "29    112000\n",
      "30     34644\n",
      "31     61192\n",
      "34     11223\n",
      "36     52132\n",
      "37     94211\n",
      "38     93076\n",
      "39     35229\n",
      "40     34216\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "numeric_data = kddcup_data.select_dtypes(include=[np.number])\n",
    "\n",
    "# Detect outliers using IQR method\n",
    "print(\"\\nOutlier Detection:\")\n",
    "Q1 = numeric_data.quantile(0.25)\n",
    "Q3 = numeric_data.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "outliers = ((numeric_data < (Q1 - 1.5 * IQR)) | (numeric_data > (Q3 + 1.5 * IQR))).sum()\n",
    "\n",
    "print(\"Outliers detected in columns:\")\n",
    "print(outliers[outliers > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **5.2.4 Handle Missing Values and Outliers**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nettrafficguard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
